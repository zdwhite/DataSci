{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dmitry Melnikov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to classify Titanic passengers as survivors based on the data provided about these passengers. The goal is to train various algorithms and to use them to predict whether the passenger would survive or not.\n",
    "\n",
    "  * This  project is focused on using data analytics and deep learning algorithms to predict survival chance of passengers of Titanic. The data is obtained from public source and includes description of passenger's details such as class of travel, gender, age and survival data. I have used publicly availiable classification algorythms and compared their performance.\n",
    "  * To analyze this data I used publicly avaliable classification algorithms and find the best one for this problem from Scikit-learn tool kit [scikit-learn.org]\n",
    "  * This project is focus on classification of passengers between survived/not survived classes.\n",
    "  * I was interested to see how well the algorithms would be able to predict the survival of passengers based on the information about them.\n",
    "  * This was an individual project.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this project is availiable from one of Kaggle competition submissions. __[Data Source](https://www.kaggle.com/c/titanic/data)__ I will be using publicly available classification algorithms from __[Scikit](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning)__. I have used multiple algorithms presented there and evaluated their performance. I have used seven different algorithms and compared their performance.\n",
    "\n",
    "The following fields with show combination of markdown cells and code cells to make it easier to see the development process of this project and how I've arrived at the results. \n",
    "\n",
    "The first step in the project was to inspect the data and correctly indentify which fields could be ommited, which fields were important for modeling and which alphanumeric fields had to be converted to numeric fields for the purposes of fitting into inputs of modeling algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hogeboom, Mrs. John C (Anna Andrews)</td>\n",
       "      <td>female</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D11</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                  Name  \\\n",
       "765          766         1       1  Hogeboom, Mrs. John C (Anna Andrews)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch Ticket     Fare Cabin Embarked  \n",
       "765  female  51.0      1      0  13502  77.9583   D11        S  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load test and train data sets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The first step is to load the provided file 'train.csv', parse the data with pandas and review the given fields. The fields are as follows:**\n",
    "* PassengerId - ID of the passengers, just a key in the table\n",
    "* Survived - zero or one, shows whether the passengers survived or not\n",
    "* Pclass - class of travel, one is highest, equal to first class on modern airplanes\n",
    "* Name - the name of passenger, with title\n",
    "* Sex - the sex of passenger\n",
    "* Age - the age of passenger\n",
    "* SibSp - number of siblings/spouses abroad the ship\n",
    "* Parch - number of parent/children abroad the ship\n",
    "* Ticket - alphanumeric value of ticket\n",
    "* Fare - cost of ticket\n",
    "* Cabin - cabin/room number\n",
    "* Embarked - which port the passenger embarked from, C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next step is to start inspecting the data for unnecessary information. **\n",
    "First choice is to remove the Ticket and Cabin fields since they don't convey any necessary information. I chose to drop them from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dennis, Mr. Samuel</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                Name   Sex   Age  SibSp  \\\n",
       "320          321         0       3  Dennis, Mr. Samuel  male  22.0      0   \n",
       "\n",
       "     Parch  Fare Embarked  \n",
       "320      0  7.25        S  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ticket and Cabin are alphanumeric data fields with no correlation to the survival rate. Cabin information is already captured \n",
    "#in Pclass field. Drop both fields from data set\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "train_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionaly I remove the PassengerId column since this is just a counter or a key into the database with no value to our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lefebre, Miss. Mathilde</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                     Name     Sex  Age  SibSp  Parch  \\\n",
       "229         0       3  Lefebre, Miss. Mathilde  female  NaN      3      1   \n",
       "\n",
       "        Fare Embarked  \n",
       "229  25.4667        S  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Additionaly drop PassengerId since it's just a counter\n",
    "train_df = train_df.drop(['PassengerId'], axis=1)\n",
    "train_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I identify empty fields and see which values need to be populated in order to fir the modeling software requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find empty fields\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Embarked has 2 empty fields. I chose to fill them in with most common value of S, this should have minimal effect on modeling results. Next since we are operating on the 'Embarked' column we can begin the process of converting alphanumeric values to numeric bins in order to fit the requirement of modeling software. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                    Name     Sex   Age  SibSp  Parch  \\\n",
       "2         1       3  Heikkinen, Miss. Laina  female  26.0      0      0   \n",
       "\n",
       "    Fare  Embarked  \n",
       "2  7.925         0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert Embarked to numeric fields. Fill in empty fields first\n",
    "\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna('S')\n",
    "train_df['Embarked'] = train_df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "train_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to verify that all of the 'Embarked' fields are filled in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find empty fields\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to fill in the 'Age' column. This was a concerning situation, considering how many values were missing and how critical it seems to the modeling. I have researched and experimented with multiple way of handling this issue. One way included trying to guess the age of the passengers based on other data, essentially using predictive modeling for one of the variables in predictive modeling. Another way would be to assign the mean value to all of the unknown ages. I chose to leave blank ages as unknown and populate those cells as -1. This would preserve the initial integrity of data without compromising our ability to model it in the popular algorithms that require all of the rows to be filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Survived, Pclass, Name, Sex, Age, SibSp, Parch, Fare, Embarked]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Age'] = train_df['Age'].fillna(-1)\n",
    "#verify that all missing Age values were replaced\n",
    "A = train_df.query('Age != Age')\n",
    "A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all of the empty 'Age' rows have been filled in. Next is to convert 'Sex' column values from male/female to numeric representation and verify correct table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Sex field to numeric value\n",
    "train_df['Sex'] = train_df['Sex'].map( {'male': 0, 'female': 1} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Williams, Mr. Leslie</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                  Name  Sex   Age  SibSp  Parch  Fare  \\\n",
       "735         0       3  Williams, Mr. Leslie    0  28.5      0      0  16.1   \n",
       "\n",
       "     Embarked  \n",
       "735         0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify correct table format\n",
    "train_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Fare' column can be reduced down into bin for each quartile increment of the Fare value. This is especially convenient since the Fare cost corresponds to the class of travel so it makes sense to simplify it for our modeling purposes. We create new column 'TicketPrice' and delete the 'Fare' column. We also going to remove the 'Name' column. After experimentation of trying to parse out titles and process them as separate variables it made no changes to the results. Also titles in this data sets are mostly 'Mr' or 'Miss/Mrs/Ms' which correspond to the 'Sex' values we already have. Other values included 1-off titles like 'Captn' which would not be helpful if the data set is broken in parts between testing and training sets. So I have decided to remove that field from modeling and focus on other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate ticket costs into 4 quartile increment for easier computation\n",
    "\n",
    "bins = (-1, 0, 8, 15, 31, 1000)\n",
    "groups = ['0', '1', '2', '3', '4']\n",
    "\n",
    "train_df['TicketPrice'] = pd.cut(train_df['Fare'], bins, labels=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Christmann, Mr. Emil</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass                  Name  Sex   Age  SibSp  Parch  Fare  \\\n",
       "90         0       3  Christmann, Mr. Emil    0  29.0      0      0  8.05   \n",
       "\n",
       "    Embarked TicketPrice  \n",
       "90         0           2  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  SibSp  Parch  Embarked TicketPrice\n",
       "517         0       3    0 -1.0      0      0         2           3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Name and Fare column.\n",
    "\n",
    "train_df = train_df.drop(['Name', 'Fare'], axis=1)\n",
    "train_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data set is now cleaned up, formatted and ready to be used in our modeling tools**\n",
    "First step is to separate the provided data between train and testing data sets so that we can evaluate the prediction accuracy of our algorithms. This is done by the provided utility function 'train_test_split' which automatically divides the data set into X and Y matrices by a 75/25 split for train/test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing and training X and Y matrices\n",
    "\n",
    "x = train_df.drop(['Survived'], axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier algorithm selection and explanations**\n",
    "\n",
    "The first set of algorithm used for this project are the SVM Classifiers:\n",
    "\n",
    "**SVM Classifier Summary:**\n",
    "\n",
    "Also known as “Support Vector Machines” these are supervised learning methods used for classification, regression, and outlier’s detection. Advantages are SVM’s are useful with high dimensional spaces, and still operative where the number of dimensions are greater than the number of samples. It is also memory efficient while using a subset of training points whilst in the decision function. You can identify custom kernels and varying kernel functions can be specified for the decision function. \n",
    "\n",
    "Disadvantages exists for SVMs one in particular describes that probability estimates are not provided with SVM’s but rather five-fold cross-validation are used in the probability estimates.\n",
    "\n",
    "The first SVM Classifier is the standard liner classifier. The classifier algorithms are taken from the Scikit tool set. The results of their prediction are evaluated based on accuracy. The accuracy_score is the provided function with the Scikit tools that compares predicted Y matrix to the actual Y matrix (the survived/ not survived in this case). The accuracy percentage is stoged in the 'performance' dictionary in order to compare the classifing algorithms. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7802690582959642"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM Classifier, liner \n",
    "\n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, y_train)  \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "svm_liner=accuracy_score(y_test, y_pred)\n",
    "performance={}\n",
    "performance['SVM liner']=round(svm_liner*100,2)\n",
    "svm_liner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the other types of SVM classifiers - with gaussian kernel and sigmoid kernel. Very simlar code, only change is to the passed parameter to the svm function. The resulting accuracy score is once again stored in the 'performance' dictionary. Same is done for the sigmoid kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026905829596412"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM Classifier, Gaussian \n",
    "\n",
    "svclassifier = SVC(kernel='rbf')  \n",
    "svclassifier.fit(X_train, y_train)  \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "svm_gaus=accuracy_score(y_test, y_pred)\n",
    "performance['SVM Gauss']=round(svm_gaus*100,2)\n",
    "svm_gaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47533632286995514"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM Classifier, Sigmoid \n",
    "\n",
    "svclassifier = SVC(kernel='sigmoid')  \n",
    "svclassifier.fit(X_train, y_train)  \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "svm_sig=accuracy_score(y_test, y_pred)\n",
    "performance['SVM Sigmoid']=round(svm_sig*100,2)\n",
    "svm_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**k-Neighbor Classifier \"nearest neighbor\" Summary:**\n",
    "\n",
    "Described as a type of instance-based learning or non-generalizing learning, neighbors- based classification stores instances of training data and does not attempt to build a general internal model. Sort of like an election process, classification is computed based on a majority vote of the nearest neighbors of each point. After the vote a query point is assigned the data class. This data class has the most representative within the nearest neighbor of that point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7533632286995515"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k-Neighbor Classifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "knn_acc=accuracy_score(y_test, y_pred)\n",
    "performance['k-Neighbor']=round(knn_acc*100,2)\n",
    "knn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes Summary:**\n",
    "\n",
    "This classification implements the Gaussian Naive Bayes algorithm. This algorithm used in machine learning uses naïve Bayes classifiers which are a family of “probabilistic classifiers”, it mostly describes the probability of an event based on the prior knowledge of conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7443946188340808"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "y_pred = gaussian.predict(X_test)\n",
    "gaus_acc=accuracy_score(y_test, y_pred)\n",
    "performance['Gaussian Naive Bayes']=round(gaus_acc*100,2)\n",
    "gaus_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Summary:**\n",
    "\n",
    "Also a part of the family of supervised learning algorithms, the decision tree algorithms can be useful in solving regression and classification issues. This algorithm creates a model that predicts the value of a  variable by learning simple decision rules inferred from the data features. These trees can be easily visualized and understood in simple terms. [scikit-learn.org] Their disadvanges is the inability to generalize the data well in certain cases. [dataaspirant.com]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7443946188340808"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "tree_acc=accuracy_score(y_test, y_pred)\n",
    "performance['Decision Tree']=round(tree_acc*100,2)\n",
    "tree_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Summary:**\n",
    "\n",
    "The bigger picture of decision tree classifier. This algorithm builds estimator that fits multiple decision trees on various samples of the dataset and uses averaging to improve the accuracy. It is a type of ensamble learning method. This is a farly recent technique, with earliest example of it used in 1995. [Wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7892376681614349"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=200)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "rand_forest_acc=accuracy_score(y_test, y_pred)\n",
    "performance['Random Forest']=round(rand_forest_acc*100,2)\n",
    "rand_forest_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "I was hoping to find correlation between passenger's info and their predicted survival in the Titanic disaster. I was especially interested how likely were passengers to survive based on their class of travel, age and gender. I was interested in which classification algorithm is better suited to evaluate this data. \n",
    "\n",
    "After performing the above work the resulting performance is the summary of accuracy of our selected algorithms on this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM liner': 78.03,\n",
       " 'SVM Gauss': 80.27,\n",
       " 'SVM Sigmoid': 47.53,\n",
       " 'k-Neighbor': 75.34,\n",
       " 'Gaussian Naive Bayes': 74.44,\n",
       " 'Decision Tree': 74.44,\n",
       " 'Random Forest': 78.92}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on randomness of test/train data set separation and in modeling algorithms the results will vary slightly every time this notebook is ran. However some clear results can be seen independently of such factors. The worst performing algorithm is consistently the SVM Sigmoid with accuracy as low as 50% in some cases. All the other algorithms perform above 70 and sometimes up to 80 percent accuracy in predicting the survival rate. Considering how seemingly non-correlating this dataset is, this kind of accuracy surprised me. It was and important step for my understanding of data processing in relations to neural networks and classifiers in particular. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This is an individual project and I was able  to fully complete it by the deadline.  The timeline was as follows:\n",
    "\n",
    "* Nov 13 - initial set-up complete\n",
    "* Nov 19 - neural networks trained \n",
    "* Nov 27 - data is tested and analyzed\n",
    "* Dec 9 - final clean-up and submission of project\n",
    "\n",
    "Changes that had to be made to the timeline were all due to the up front work with the data. I've spent three extra days \"grooming\" the dataset. I was surprised how much preparation the data required in order to be correctly modeled. This was the most difficult part of this project for me. Decisions had to be made regarding the way to handle empty 'Age' values. Learning about various ways to handle this situation was helpful in my understanding of data processing. \n",
    "During this project I was able to learn about multiple classification algorithms, some of them were covered in class and some of the were new to me. However I feel that the CS440 course gave me a good understanding of underlying principles and conceptual background of neural networks and data modeling which allowed me to quickly understand the new algorithms. Implementation part was very easy thanks to the package I chose to use for this project.\n",
    "\n",
    "I would like to thank Dr Anderson and his CS440 lectures that helped me prepare for this project. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. “Supervised Learning.” Scikit-Learn 0.19.2,https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "\n",
    "2.\t“How Decision Tree Algorithm Works.” Dataaspirant, 21 Apr. 2017, dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/.\n",
    "3.\t“1.10. Decision Trees¶.” 1.4. Support Vector Machines - Scikit-Learn 0.19.2 Documentation, scikit-learn.org/stable/modules/tree.html#classification.\n",
    "4. “Random Forest.” Wikipedia, 8 Dec. 2018,https://en.wikipedia.org/wiki/Random_forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count for file Melnikov-Project.ipynb is 1872\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from IPython.nbformat import current\n",
    "import glob\n",
    "nbfile = glob.glob('Melnikov-Project.ipynb')\n",
    "if len(nbfile) > 1:\n",
    "    print('More than one ipynb file. Using the first one.  nbfile=', nbfile)\n",
    "with io.open(nbfile[0], 'r', encoding='utf-8') as f:\n",
    "    nb = current.read(f, 'json')\n",
    "word_count = 0\n",
    "for cell in nb.worksheets[0].cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "print('Word count for file', nbfile[0], 'is', word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
